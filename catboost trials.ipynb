{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0c118602-38e5-4332-bbe7-e9d419be1fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ranker_pipeline.py\n",
    "# ---------------------------------------------------------------\n",
    "import ast, json, joblib, warnings, networkx as nx\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import GroupKFold, GroupShuffleSplit\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import lightgbm as lgb\n",
    "from lightgbm.callback import early_stopping, log_evaluation\n",
    "from catboost import CatBoostRanker,Pool\n",
    "\n",
    "\n",
    "# ------------------------------ feature engineering -------------\n",
    "CENT_FUNCS = {\n",
    "    \"pagerank\"   : nx.pagerank,\n",
    "    \"betweenness\": nx.betweenness_centrality,\n",
    "    \"katz\"       : lambda G: nx.katz_centrality_numpy(G, alpha=0.01),\n",
    "    \"closeness\"  : nx.closeness_centrality,\n",
    "}\n",
    "KEEP_CENTS = list(CENT_FUNCS) + [\"voterank\"]      # five strongest\n",
    "\n",
    "def voterank_scores(G):\n",
    "    seeds = nx.voterank(G)\n",
    "    score = {n: 0. for n in G}\n",
    "    for r, n in enumerate(seeds[::-1], 1):\n",
    "        score[n] = r / len(seeds)\n",
    "    return score\n",
    "\n",
    "def build_node_df(df_in: pd.DataFrame) -> pd.DataFrame:\n",
    "    rows = []\n",
    "    for _, row in df_in.iterrows():\n",
    "        G = nx.from_edgelist(ast.literal_eval(row.edgelist))\n",
    "        cents = {k: f(G) for k, f in CENT_FUNCS.items()}\n",
    "        cents[\"voterank\"] = voterank_scores(G)\n",
    "        n_tok = len(G)\n",
    "\n",
    "        for node in G:\n",
    "            rec = {\n",
    "                \"language\": row.language,\n",
    "                \"sentence\": row.sentence,\n",
    "                \"node\"    : node,\n",
    "                \"n_tokens\": n_tok,\n",
    "                **{k: cents[k][node] for k in cents},\n",
    "            }\n",
    "            if \"root\" in row:              # train set\n",
    "                rec[\"target\"] = int(node == row.root)\n",
    "            rows.append(rec)\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "\n",
    "    # min-max within each sentence\n",
    "    scaler = MinMaxScaler()\n",
    "    df[KEEP_CENTS] = (\n",
    "        df.groupby(\"sentence\")[KEEP_CENTS]\n",
    "          .transform(lambda x: scaler.fit_transform(x.values.reshape(-1, 1)).ravel())\n",
    "    )\n",
    "    # categorical dtype for language\n",
    "    df[\"language\"] = df[\"language\"].astype(\"category\")\n",
    "    return df\n",
    "\n",
    "# ------------------------------ utility -------------------------\n",
    "def make_groups(sorted_sentence_ids: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Return an array of group sizes (one per sentence).\"\"\"\n",
    "    _, counts = np.unique(sorted_sentence_ids, return_counts=True)\n",
    "    return counts\n",
    "\n",
    "def sort_by_sentence(idx: np.ndarray, sentence_ids: np.ndarray):\n",
    "    order = np.argsort(sentence_ids[idx], kind=\"mergesort\")\n",
    "    return idx[order]\n",
    "\n",
    "# ------------------------------ CV & training -------------------\n",
    "def cross_validate_ranker(X: pd.DataFrame,\n",
    "                          y: np.ndarray,\n",
    "                          sid: np.ndarray,\n",
    "                          model_type: str = \"lgb\",\n",
    "                          n_splits: int = 5,\n",
    "                          seed: int = 42):\n",
    "    \"\"\"\n",
    "    Returns\n",
    "    -------\n",
    "    cv_acc   : list[float]   accuracy@1 for each fold\n",
    "    best_it  : list[int]     best trees / iterations per fold\n",
    "    models   : list          fitted fold models (optional use)\n",
    "    \"\"\"\n",
    "    gkf = GroupKFold(n_splits)\n",
    "    cv_acc, best_it, fold_models = [], [], []\n",
    "\n",
    "    for fold, (tr_idx, va_idx) in enumerate(gkf.split(X, y, sid), 1):\n",
    "        tr_idx = sort_by_sentence(tr_idx, sid)\n",
    "        va_idx = sort_by_sentence(va_idx, sid)\n",
    "\n",
    "        X_tr, y_tr, sid_tr = X.iloc[tr_idx], y[tr_idx], sid[tr_idx]\n",
    "        X_va, y_va, sid_va = X.iloc[va_idx], y[va_idx], sid[va_idx]\n",
    "\n",
    "        grp_tr = make_groups(sid_tr)\n",
    "        grp_va = make_groups(sid_va)\n",
    "\n",
    "        if model_type == \"lgb\":\n",
    "            model = lgb.LGBMRanker(\n",
    "                objective=\"lambdarank\",\n",
    "                metric=\"map\",\n",
    "                label_gain=[0, 1],\n",
    "                n_estimators=1500,\n",
    "                learning_rate=0.03,\n",
    "                num_leaves=127,\n",
    "                min_data_in_leaf=20,\n",
    "                subsample=0.8,\n",
    "                colsample_bytree=0.8,\n",
    "                random_state=seed,\n",
    "            )\n",
    "            model.fit(\n",
    "                X_tr, y_tr,\n",
    "                group=grp_tr,\n",
    "                eval_set=[(X_va, y_va)],\n",
    "                eval_group=[grp_va],\n",
    "                eval_at=[1],\n",
    "                categorical_feature=[\"language\"],\n",
    "                callbacks=[early_stopping(50), log_evaluation(100)],\n",
    "            )\n",
    "\n",
    "        elif model_type == \"cat\":\n",
    "            if not CATBOOST_OK:\n",
    "                raise ValueError(\"CatBoost is not installed.\")\n",
    "            pool_tr = Pool(\n",
    "                X_tr,\n",
    "                y_tr,\n",
    "                group_id=pd.Series(sid_tr).astype(\"category\").cat.codes,\n",
    "                cat_features=[X_tr.columns.get_loc(\"language\")],\n",
    "            )\n",
    "            pool_va = Pool(\n",
    "                X_va,\n",
    "                y_va,\n",
    "                group_id=pd.Series(sid_va).astype(\"category\").cat.codes,\n",
    "                cat_features=[X_tr.columns.get_loc(\"language\")],\n",
    "            )\n",
    "            model = CatBoostRanker(\n",
    "                iterations=1500,\n",
    "                learning_rate=0.07,\n",
    "                depth=6,\n",
    "                loss_function=\"YetiRankPairwise\",\n",
    "                random_seed=seed,\n",
    "                early_stopping_rounds=50,\n",
    "                verbose=False,\n",
    "            )\n",
    "            model.fit(pool_tr, eval_set=pool_va, verbose=False)\n",
    "\n",
    "        else:\n",
    "            raise ValueError(\"model_type must be 'lgb' or 'cat'\")\n",
    "\n",
    "        # accuracy@1 on this fold\n",
    "        prob = model.predict(X_va)\n",
    "        acc1 = (\n",
    "            pd.DataFrame({\"sid\": sid_va, \"target\": y_va, \"prob\": prob})\n",
    "              .loc[lambda d: d.groupby(\"sid\")[\"prob\"].idxmax()]\n",
    "              [\"target\"].mean()\n",
    "        )\n",
    "\n",
    "        cv_acc.append(acc1)\n",
    "        fold_models.append(model)\n",
    "        best_it.append(\n",
    "            model.best_iteration_ if model_type == \"lgb\"\n",
    "            else model.get_best_iteration()\n",
    "        )\n",
    "        print(f\"fold {fold}: acc@1 = {acc1:.3f}  |  best_iter = {best_it[-1]}\")\n",
    "\n",
    "    return cv_acc, best_it, fold_models\n",
    "\n",
    "def train_full_ranker(X: pd.DataFrame,\n",
    "                      y: np.ndarray,\n",
    "                      sid: np.ndarray,\n",
    "                      best_iter: int,\n",
    "                      model_type: str = \"lgb\",\n",
    "                      seed: int = 42):\n",
    "    order = np.argsort(sid, kind=\"mergesort\")\n",
    "    X_all, y_all, sid_all = X.iloc[order], y[order], sid[order]\n",
    "    grp_all = make_groups(sid_all)\n",
    "\n",
    "    if model_type == \"lgb\":\n",
    "        model = lgb.LGBMRanker(\n",
    "            objective=\"lambdarank\",\n",
    "            metric=\"map\",\n",
    "            label_gain=[0, 1],\n",
    "            n_estimators=best_iter,\n",
    "            learning_rate=0.03,\n",
    "            num_leaves=127,\n",
    "            min_data_in_leaf=20,\n",
    "            subsample=0.8,\n",
    "            colsample_bytree=0.8,\n",
    "            random_state=seed,\n",
    "        )\n",
    "        model.fit(\n",
    "            X_all, y_all,\n",
    "            group=grp_all,\n",
    "            categorical_feature=[\"language\"],\n",
    "        )\n",
    "    else:   # cat\n",
    "        pool_all = Pool(\n",
    "            X_all,\n",
    "            y_all,\n",
    "            group_id=pd.Series(sid_all).astype(\"category\").cat.codes,\n",
    "            cat_features=[X_all.columns.get_loc(\"language\")],\n",
    "        )\n",
    "        model = CatBoostRanker(\n",
    "            iterations=best_iter,\n",
    "            learning_rate=0.07,\n",
    "            depth=6,\n",
    "            loss_function=\"YetiRankPairwise\",\n",
    "            random_seed=seed,\n",
    "            verbose=False,\n",
    "        )\n",
    "        model.fit(pool_all, verbose=False)\n",
    "\n",
    "    return model\n",
    "\n",
    "# ------------------------------ prediction / submission ----------\n",
    "\n",
    "def predict_root(model, node_df: pd.DataFrame, model_type: str):\n",
    "    FEATURES = KEEP_CENTS + [\"n_tokens\", \"language\"]\n",
    "\n",
    "    if model_type == \"cat\":\n",
    "        # 1️⃣ sort so rows for the SAME (language, sentence) stay contiguous\n",
    "        node_df = (\n",
    "            node_df.sort_values([\"language\", \"sentence\"], kind=\"mergesort\")\n",
    "                   .reset_index(drop=True)\n",
    "        )\n",
    "\n",
    "        # 2️⃣ build a UNIQUE query id = (language, sentence)\n",
    "        lang_sent = list(zip(node_df[\"language\"], node_df[\"sentence\"]))\n",
    "        group_codes = pd.Series(lang_sent).astype(\"category\").cat.codes\n",
    "\n",
    "        pool = Pool(\n",
    "            node_df[FEATURES],\n",
    "            group_id=group_codes,\n",
    "            cat_features=[node_df[FEATURES].columns.get_loc(\"language\")]\n",
    "        )\n",
    "        prob = model.predict(pool)\n",
    "\n",
    "    else:                         # LightGBM, XGBoost …\n",
    "        prob = model.predict(node_df[FEATURES])\n",
    "\n",
    "    node_df[\"prob\"] = prob\n",
    "\n",
    "    # pick top node per (language, sentence)\n",
    "    root_pred = (\n",
    "        node_df.loc[node_df.groupby([\"language\", \"sentence\"])[\"prob\"].idxmax()]\n",
    "               [[\"language\", \"sentence\", \"node\"]]\n",
    "               .rename(columns={\"node\": \"root\"})\n",
    "    )\n",
    "    return root_pred\n",
    "\n",
    "\n",
    "def build_submission(test_raw: pd.DataFrame,\n",
    "                     root_pred: pd.DataFrame,\n",
    "                     path: str = \"submission.csv\"):\n",
    "    submission = (\n",
    "        test_raw[[\"id\", \"language\", \"sentence\"]]\n",
    "          .merge(root_pred, on=[\"language\", \"sentence\"], how=\"left\")\n",
    "          [[\"id\", \"root\"]]\n",
    "    )\n",
    "    submission.to_csv(path, index=False)\n",
    "    print(f\"✓ {path} written: {submission.shape[0]} rows\")\n",
    "    return submission\n",
    "\n",
    "# ------------------------------ offline eval ---------------------\n",
    "def offline_eval(submission: pd.DataFrame,\n",
    "                 test_raw: pd.DataFrame,\n",
    "                 labeled_path: str = \"datasets/labeled_test.csv\"):\n",
    "    if not Path(labeled_path).exists():\n",
    "        print(\"labeled_test.csv not found – skipped offline scoring.\")\n",
    "        return\n",
    "    labeled = pd.read_csv(labeled_path)\n",
    "    merged  = labeled.merge(submission, on=\"id\", suffixes=(\"_true\", \"_pred\"))\n",
    "    acc     = (merged.root_true == merged.root_pred).mean()\n",
    "    print(f\"Offline sentence accuracy = {acc:0.3f}\")\n",
    "    # per-language table\n",
    "    acc_by_lang = (\n",
    "        merged.merge(test_raw[[\"id\", \"language\"]], on=\"id\")\n",
    "              .assign(hit=lambda d: d.root_true == d.root_pred)\n",
    "              .groupby(\"language\")[\"hit\"].mean()\n",
    "              .sort_values(ascending=False)\n",
    "    )\n",
    "    display(acc_by_lang)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c7972b1f-a9cf-46d9-b8bd-05091e3f274a",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN = pd.read_csv(\"datasets/train.csv\")\n",
    "TEST  = pd.read_csv(\"datasets/test.csv\")\n",
    "\n",
    "train_nodes = build_node_df(TRAIN)\n",
    "test_nodes  = build_node_df(TEST)\n",
    "\n",
    "FEATURES = KEEP_CENTS + [\"n_tokens\", \"language\"]\n",
    "X_full   = train_nodes[FEATURES]\n",
    "y_full   = train_nodes[\"target\"].values\n",
    "sid      = train_nodes[\"sentence\"].values\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b3781a92-72e6-45e5-bd2e-933a2768ae5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 1: acc@1 = 0.470  |  best_iter = 178\n",
      "fold 2: acc@1 = 0.470  |  best_iter = 145\n",
      "fold 3: acc@1 = 0.590  |  best_iter = 158\n",
      "fold 4: acc@1 = 0.530  |  best_iter = 114\n",
      "fold 5: acc@1 = 0.460  |  best_iter = 89\n",
      "CV acc@1  mean = 0.504\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------------- choose model\n",
    "MODEL_TYPE = \"cat\"      # \"lgb\" or \"cat\"\n",
    "# ------------------------------------------------------------- CV\n",
    "cv_acc, best_it, _ = cross_validate_ranker(\n",
    "    X_full, y_full, sid, model_type=MODEL_TYPE, n_splits=5\n",
    ")\n",
    "print(\"CV acc@1  mean =\", np.mean(cv_acc).round(3))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6086dc68-9d53-40e5-a207-21faa80d63bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Refitting cat with 137 iterations\n",
      "✓ submission.csv written: 10395 rows\n",
      "Offline sentence accuracy = 0.345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3z/gd5140_d36qfgyc8rvqk3dth0000gn/T/ipykernel_29204/1654930559.py:248: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  node_df.loc[node_df.groupby([\"language\", \"sentence\"])[\"prob\"].idxmax()]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "language\n",
       "Icelandic     0.452525\n",
       "Russian       0.438384\n",
       "Arabic        0.434343\n",
       "Indonesian    0.430303\n",
       "Swedish       0.420202\n",
       "Finnish       0.404040\n",
       "Polish        0.400000\n",
       "Czech         0.395960\n",
       "Turkish       0.369697\n",
       "German        0.369697\n",
       "Korean        0.359596\n",
       "Chinese       0.331313\n",
       "English       0.327273\n",
       "Thai          0.327273\n",
       "French        0.311111\n",
       "Spanish       0.311111\n",
       "Galician      0.292929\n",
       "Portuguese    0.288889\n",
       "Italian       0.264646\n",
       "Hindi         0.234343\n",
       "Japanese      0.088889\n",
       "Name: hit, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "final_iter = int(np.round(np.mean(best_it)))\n",
    "print(\"Refitting\", MODEL_TYPE, \"with\", final_iter, \"iterations\")\n",
    "\n",
    "# ------------------------------------------------------------- full train\n",
    "final_model = train_full_ranker(\n",
    "    X_full, y_full, sid, best_iter=final_iter, model_type=MODEL_TYPE\n",
    ")\n",
    "\n",
    "# save artefacts\n",
    "joblib.dump(final_model, f\"{MODEL_TYPE}_ranker_final.pkl\")\n",
    "meta = {\"iterations\": final_iter,\n",
    "        \"language_categories\": train_nodes[\"language\"].cat.categories.tolist()}\n",
    "json.dump(meta, open(f\"{MODEL_TYPE}_meta.json\", \"w\"))\n",
    "\n",
    "# ------------------------------------------------------------- predict & submit\n",
    "root_pred_df = predict_root(final_model, test_nodes, model_type=MODEL_TYPE)\n",
    "submission   = build_submission(TEST, root_pred_df, path=f\"{MODEL_TYPE}_submission.csv\")\n",
    "\n",
    "# ------------------------------------------------------------- offline eval\n",
    "offline_eval(submission, TEST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "951b49c3-ca62-4f63-977c-e8d4870f2bb2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (omnixai)",
   "language": "python",
   "name": "omnixai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
