{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab294402-2f7d-4054-b6ae-fe762875b745",
   "metadata": {},
   "outputs": [],
   "source": [
    "CENTRALITY_FUNCS = {\n",
    "    \"degree\"       : nx.degree_centrality,\n",
    "    \"closeness\"    : nx.closeness_centrality,\n",
    "    \"harmonic\"     : nx.harmonic_centrality,\n",
    "    \"betweenness\"  : nx.betweenness_centrality,\n",
    "    \"load\"         : nx.load_centrality,\n",
    "    \"eigenvector\"  : lambda G: nx.eigenvector_centrality_numpy(G),\n",
    "    \"katz\"         : lambda G: nx.katz_centrality_numpy(G, alpha=0.01),\n",
    "    \"pagerank\"     : nx.pagerank,\n",
    "    \"current_flow_betweenness\": nx.current_flow_betweenness_centrality,\n",
    "    \"current_flow_closeness\"  : nx.current_flow_closeness_centrality,\n",
    "    \"subgraph\"     : nx.subgraph_centrality,\n",
    "    \"communicability_betw\"    : nx.communicability_betweenness_centrality,\n",
    "    \"percolation\"  : nx.percolation_centrality,\n",
    "    \"second_order\" : nx.second_order_centrality,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2ace07a4-0f0e-4fba-baf5-703cf7c6b198",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np, networkx as nx, ast, lightgbm as lgb\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from lightgbm import LGBMRanker, early_stopping, log_evaluation\n",
    "\n",
    "\n",
    "\n",
    "CENT_FUNCS = {\n",
    "    \"degree\"       : nx.degree_centrality,\n",
    "    \"harmonic\"     : nx.harmonic_centrality,\n",
    "    \"pagerank\": nx.pagerank,\n",
    "    \"betweenness\": nx.betweenness_centrality,\n",
    "    \"katz\": lambda G: nx.katz_centrality_numpy(G, alpha=0.01),\n",
    "    \"closeness\": nx.closeness_centrality,\n",
    "    \"subgraph\"     : nx.subgraph_centrality,\n",
    "\n",
    "}\n",
    "\n",
    "def voterank_scores(G):\n",
    "    seeds = nx.voterank(G)\n",
    "    s = {n:0. for n in G}\n",
    "    for r,n in enumerate(seeds[::-1],1): s[n]=r/len(seeds)\n",
    "    return s\n",
    "\n",
    "def build(df):\n",
    "    rows=[]\n",
    "    for _,row in df.iterrows():\n",
    "        G = nx.from_edgelist(ast.literal_eval(row.edgelist))\n",
    "        cents={k:f(G) for k,f in CENT_FUNCS.items()}\n",
    "        cents['voterank']=voterank_scores(G)\n",
    "        n_tok=len(G)\n",
    "        for n in G:\n",
    "            rec={'language':row.language,\n",
    "                 'sentence':row.sentence,\n",
    "                 'node':n,\n",
    "                 'n_tokens':n_tok,\n",
    "                 **{k:cents[k][n] for k in cents}}\n",
    "            if 'root' in row: rec['target']=int(n==row.root)\n",
    "            rows.append(rec)\n",
    "    df_out=pd.DataFrame(rows)\n",
    "    cent_cols=list(CENT_FUNCS)+['voterank']\n",
    "    scaler=MinMaxScaler()\n",
    "    df_out[cent_cols]=(\n",
    "        df_out.groupby('sentence')[cent_cols]\n",
    "              .transform(lambda x: scaler.fit_transform(x.values.reshape(-1,1)).ravel())\n",
    "    )\n",
    "    return df_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "467cdc80-f675-40b2-8c6f-e05657a59ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_raw=pd.read_csv('datasets/train.csv')\n",
    "test_raw =pd.read_csv('datasets/test.csv')\n",
    "\n",
    "train_nodes=build(train_raw)\n",
    "test_nodes =build(test_raw )\n",
    "for df in (train_nodes, test_nodes):\n",
    "    df['language'] = df['language'].astype('category')\n",
    "\n",
    "KEEP_CENTS=['pagerank','betweenness','katz','voterank','closeness','degree', 'harmonic']\n",
    "FEATURES  =KEEP_CENTS+['n_tokens','language']\n",
    "cat_feats = ['language']\n",
    "\n",
    "X      = train_nodes[FEATURES]\n",
    "y      = train_nodes['target'].values\n",
    "#groups = train_nodes['sentence'].values\n",
    "#gsize  = train_nodes.groupby('sentence').size().loc[groups].values  # per row\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6283e9a1-da7b-43d9-bcb0-eb25c27638cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ------------ NEW: reserve 10 % sentences as a blind hold-out ------------\n",
    "# from sklearn.model_selection import GroupShuffleSplit\n",
    "# gss = GroupShuffleSplit(n_splits=1, test_size=0.10, random_state=42)\n",
    "# train_idx, hold_idx = next(gss.split(X, y, groups))\n",
    "# # -------------------------------------------------------------------------\n",
    "\n",
    "# # Use only train_idx for CV and model selection\n",
    "# X_tr, y_tr        = X.iloc[train_idx], y[train_idx]\n",
    "# groups_tr         = groups[train_idx]\n",
    "# gsize_tr          = gsize[train_idx]\n",
    "\n",
    "# # Hold-out set (never touched until final evaluation)\n",
    "# X_hold, y_hold    = X.iloc[hold_idx], y[hold_idx]\n",
    "# groups_hold       = groups[hold_idx]\n",
    "# gsize_hold        = gsize[hold_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7d2cd1d9-2928-4230-a6fd-343ab6eb78c0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np, pandas as pd, lightgbm as lgb\n",
    "from lightgbm.callback import early_stopping, log_evaluation\n",
    "from sklearn.model_selection import GroupKFold\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# helper: turn an array of sentence-ids into “group sizes” vector\n",
    "# ---------------------------------------------------------------\n",
    "def make_groups(sent_ids: np.ndarray):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    sent_ids : 1-D array of sentence identifiers **already sorted**\n",
    "               so identical ids are contiguous.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    sizes : 1-D array, len = #sentences, each entry = #nodes in that sentence\n",
    "    \"\"\"\n",
    "    _, counts = np.unique(sent_ids, return_counts=True)\n",
    "    return counts\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# prepare data\n",
    "# ---------------------------------------------------------------\n",
    "FEATURES   = KEEP_CENTS + ['n_tokens', 'language']\n",
    "cat_feats  = ['language']          # column names (because X is a DataFrame)\n",
    "\n",
    "X_full = train_nodes[FEATURES]\n",
    "y_full = train_nodes['target'].values\n",
    "sid    = train_nodes['sentence'].values     # sentence ids\n",
    "\n",
    "gkf = GroupKFold(5)\n",
    "val_acc = []\n",
    "\n",
    "cv_best_iters = []\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c485bdf5-3d76-47a9-acec-98de7d341bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "lang_cats = train_nodes[\"language\"].cat.categories.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "973f2518-c4b6-4705-8334-2c55ae16e672",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Arabic',\n",
       " 'Chinese',\n",
       " 'Czech',\n",
       " 'English',\n",
       " 'Finnish',\n",
       " 'French',\n",
       " 'Galician',\n",
       " 'German',\n",
       " 'Hindi',\n",
       " 'Icelandic',\n",
       " 'Indonesian',\n",
       " 'Italian',\n",
       " 'Japanese',\n",
       " 'Korean',\n",
       " 'Polish',\n",
       " 'Portuguese',\n",
       " 'Russian',\n",
       " 'Spanish',\n",
       " 'Swedish',\n",
       " 'Thai',\n",
       " 'Turkish']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lang_cats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4d64659b-7a1a-4e54-8811-19683b0936a4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Total groups: 400, total data: 157986\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001042 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 157986, number of used features: 9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Total groups: 100, total data: 39493\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\tvalid_0's map@1: 0.4\n",
      "Early stopping, best iteration is:\n",
      "[3]\tvalid_0's map@1: 0.46\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "fold 1 accuracy@1 = 0.460\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Total groups: 400, total data: 157999\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001009 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1774\n",
      "[LightGBM] [Info] Number of data points in the train set: 157999, number of used features: 9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Total groups: 100, total data: 39480\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\tvalid_0's map@1: 0.5\n",
      "[100]\tvalid_0's map@1: 0.49\n",
      "Early stopping, best iteration is:\n",
      "[65]\tvalid_0's map@1: 0.55\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "fold 2 accuracy@1 = 0.550\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Total groups: 400, total data: 157964\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000397 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1776\n",
      "[LightGBM] [Info] Number of data points in the train set: 157964, number of used features: 9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Total groups: 100, total data: 39515\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\tvalid_0's map@1: 0.54\n",
      "[100]\tvalid_0's map@1: 0.56\n",
      "Early stopping, best iteration is:\n",
      "[64]\tvalid_0's map@1: 0.59\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "fold 3 accuracy@1 = 0.590\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Total groups: 400, total data: 157968\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000967 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1775\n",
      "[LightGBM] [Info] Number of data points in the train set: 157968, number of used features: 9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Total groups: 100, total data: 39511\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\tvalid_0's map@1: 0.54\n",
      "Early stopping, best iteration is:\n",
      "[26]\tvalid_0's map@1: 0.6\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "fold 4 accuracy@1 = 0.600\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Total groups: 400, total data: 157999\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001124 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1779\n",
      "[LightGBM] [Info] Number of data points in the train set: 157999, number of used features: 9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Total groups: 100, total data: 39480\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\tvalid_0's map@1: 0.47\n",
      "Early stopping, best iteration is:\n",
      "[49]\tvalid_0's map@1: 0.48\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "fold 5 accuracy@1 = 0.480\n",
      "CV accuracy@1 = 0.536\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for fold, (tr_idx, va_idx) in enumerate(gkf.split(X_full, y_full, sid), 1):\n",
    "\n",
    "    # ---- sort TRAIN rows sentence-contiguously ----\n",
    "    order_tr  = np.argsort(sid[tr_idx], kind='mergesort')\n",
    "    X_tr      = X_full.iloc[tr_idx].iloc[order_tr]\n",
    "    y_tr      = y_full[tr_idx][order_tr]\n",
    "    sid_tr    = sid[tr_idx][order_tr]\n",
    "    grp_tr    = make_groups(sid_tr)\n",
    "\n",
    "    # ---- sort VALID rows sentence-contiguously ----\n",
    "    order_va  = np.argsort(sid[va_idx], kind='mergesort')\n",
    "    X_va      = X_full.iloc[va_idx].iloc[order_va]\n",
    "    y_va      = y_full[va_idx][order_va]\n",
    "    sid_va    = sid[va_idx][order_va]\n",
    "    grp_va    = make_groups(sid_va)\n",
    "\n",
    "    # ---- model ----\n",
    "    ranker = lgb.LGBMRanker(\n",
    "        objective      = 'lambdarank',\n",
    "        metric         = 'map',\n",
    "        label_gain     = [0, 1],\n",
    "        n_estimators   = 1500,\n",
    "        learning_rate  = 0.03,\n",
    "        num_leaves     = 127,\n",
    "        min_data_in_leaf = 20,\n",
    "        subsample      = 0.8,\n",
    "        colsample_bytree = 0.8,\n",
    "        random_state   = 42,\n",
    "    )\n",
    "\n",
    "    ranker.fit(\n",
    "        X_tr, y_tr,\n",
    "        group            = grp_tr,\n",
    "        eval_set         = [(X_va, y_va)],\n",
    "        eval_group       = [grp_va],\n",
    "        eval_at          = [1],                 # MAP@1 == accuracy@1\n",
    "        categorical_feature = cat_feats,\n",
    "        callbacks        = [early_stopping(50), log_evaluation(50)],\n",
    "    )\n",
    "\n",
    "    # ---------- accuracy@1 on this fold ----------\n",
    "    prob = ranker.predict(X_va)\n",
    "    sent_acc = (\n",
    "        pd.DataFrame({'sid': sid_va, 'target': y_va, 'prob': prob})\n",
    "          .loc[lambda d: d.groupby('sid')['prob'].idxmax()]\n",
    "          ['target']\n",
    "          .mean()\n",
    "    )\n",
    "    val_acc.append(sent_acc)\n",
    "    print(f\"fold {fold} accuracy@1 = {sent_acc:.3f}\")\n",
    "    cv_best_iters.append(ranker.best_iteration_) \n",
    "\n",
    "print(\"CV accuracy@1 =\", np.mean(val_acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "57f355ef-938a-4a9e-9a9e-3ef73141bbd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best iters per fold: [3, 65, 64, 26, 49]\n",
      "using 41 trees for final model\n"
     ]
    }
   ],
   "source": [
    "print(\"best iters per fold:\", cv_best_iters)\n",
    "final_num_boost = int(np.round(np.mean(cv_best_iters)))   # or max()\n",
    "print(\"using\", final_num_boost, \"trees for final model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "08327d33-1bfb-4101-a8d3-9a2a2ab71131",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Total groups: 500, total data: 197479\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001208 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1777\n",
      "[LightGBM] [Info] Number of data points in the train set: 197479, number of used features: 9\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMRanker(colsample_bytree=0.8, label_gain=[0, 1], learning_rate=0.03,\n",
       "           metric=&#x27;map&#x27;, min_data_in_leaf=20, n_estimators=41, num_leaves=127,\n",
       "           objective=&#x27;lambdarank&#x27;, random_state=42, subsample=0.8)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LGBMRanker</div></div><div><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>LGBMRanker(colsample_bytree=0.8, label_gain=[0, 1], learning_rate=0.03,\n",
       "           metric=&#x27;map&#x27;, min_data_in_leaf=20, n_estimators=41, num_leaves=127,\n",
       "           objective=&#x27;lambdarank&#x27;, random_state=42, subsample=0.8)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LGBMRanker(colsample_bytree=0.8, label_gain=[0, 1], learning_rate=0.03,\n",
       "           metric='map', min_data_in_leaf=20, n_estimators=41, num_leaves=127,\n",
       "           objective='lambdarank', random_state=42, subsample=0.8)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "order   = np.argsort(sid, kind='mergesort')      # keep groups contiguous\n",
    "X_all   = X_full.iloc[order]\n",
    "y_all   = y_full[order]\n",
    "grp_all = make_groups(sid[order])\n",
    "\n",
    "ranker_final = lgb.LGBMRanker(\n",
    "    objective='lambdarank',\n",
    "    metric='map',\n",
    "    label_gain=[0,1],\n",
    "    n_estimators=final_num_boost,      # <<<<<<<<<<\n",
    "    learning_rate=0.03,\n",
    "    num_leaves=127,\n",
    "    min_data_in_leaf=20,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "ranker_final.fit(\n",
    "    X_all, y_all,\n",
    "    group=grp_all,\n",
    "    categorical_feature=cat_feats\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "04c6cff7-3c8b-45bb-9a33-0d51ff7c3785",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib, json\n",
    "\n",
    "joblib.dump(ranker_final, \"lgbm_ranker_final.pkl\")\n",
    "\n",
    "with open(\"final_meta.json\", \"w\") as fp:\n",
    "    json.dump({\n",
    "        \"num_boost_round\": final_num_boost,\n",
    "        \"language_categories\": lang_cats          # <-- save them\n",
    "    }, fp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9d42cab9-8f5f-4acf-8252-2fae218bdacb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model has 41 trees\n"
     ]
    }
   ],
   "source": [
    "ranker_final = joblib.load(\"lgbm_ranker_final.pkl\")\n",
    "print(\"model has\", ranker_final.booster_.num_trees(), \"trees\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58801600-f444-486e-926d-ddee7042fde6",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "511056cc-ec3e-4b25-822d-efa63fc90344",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "✓ submission.csv written: (10395, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3z/gd5140_d36qfgyc8rvqk3dth0000gn/T/ipykernel_48122/2823900920.py:23: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  .loc[test_nodes.groupby(['language', 'sentence'])['prob'].idxmax()]\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# 0. load model + meta --------------------------------------------------\n",
    "ranker_final = joblib.load(\"lgbm_ranker_final.pkl\")\n",
    "with open(\"final_meta.json\") as fp:\n",
    "    meta = json.load(fp)\n",
    "lang_cats = meta[\"language_categories\"]\n",
    "\n",
    "# 1. build node-level frame for competition test set --------------------\n",
    "#test_raw   = pd.read_csv(\"datasets/test.csv\")\n",
    "#test_nodes = build(test_raw)\n",
    "\n",
    "# 2. align language codes ----------------------------------------------\n",
    "test_nodes[\"language\"] = pd.Categorical(test_nodes[\"language\"], categories=lang_cats)\n",
    "\n",
    "# 3. predict and create submission -------------------------------------\n",
    "#FEATURES = ['pagerank','betweenness','katz','voterank','closeness','n_tokens','language']\n",
    "probs = ranker_final.predict(test_nodes[FEATURES])\n",
    "test_nodes[\"prob\"] = probs\n",
    "\n",
    "root_pred = (\n",
    "    test_nodes\n",
    "      .loc[test_nodes.groupby(['language', 'sentence'])['prob'].idxmax()]\n",
    "      .rename(columns={'node': 'root'})\n",
    "      [['language', 'sentence', 'root']]\n",
    ")\n",
    "\n",
    "\n",
    "submission = (\n",
    "    test_raw[['id', 'language', 'sentence']]\n",
    "      .merge(root_pred, on=['language', 'sentence'], how='left')\n",
    "      [['id', 'root']]\n",
    ")\n",
    "submission.to_csv(\"submission.csv\", index=False)\n",
    "print(\"✓ submission.csv written:\", submission.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d2955388-618e-4b06-bf0d-1ef9b18476d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Offline sentence accuracy = 0.355\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "language\n",
       "Icelandic     0.450505\n",
       "Russian       0.444444\n",
       "Swedish       0.436364\n",
       "Arabic        0.434343\n",
       "Indonesian    0.430303\n",
       "Finnish       0.408081\n",
       "Polish        0.406061\n",
       "Czech         0.393939\n",
       "Turkish       0.371717\n",
       "German        0.359596\n",
       "Korean        0.359596\n",
       "Galician      0.347475\n",
       "English       0.345455\n",
       "Spanish       0.341414\n",
       "French        0.333333\n",
       "Thai          0.331313\n",
       "Chinese       0.319192\n",
       "Italian       0.315152\n",
       "Portuguese    0.311111\n",
       "Hindi         0.232323\n",
       "Japanese      0.074747\n",
       "Name: hit, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 4. optional offline check against labeled_test.csv -------------------\n",
    "if Path(\"datasets/labeled_test.csv\").exists():\n",
    "    labeled  = pd.read_csv(\"datasets/labeled_test.csv\")   # has id,root\n",
    "    merged   = labeled.merge(submission, on=\"id\", suffixes=(\"_true\",\"_pred\"))\n",
    "    acc      = (merged.root_true == merged.root_pred).mean()\n",
    "    print(f\"Offline sentence accuracy = {acc:0.3f}\")\n",
    "    # (extra) Confusion table of languages\n",
    "    acc_by_lang = (\n",
    "        merged\n",
    "          .merge(test_raw[[\"id\",\"language\"]], on=\"id\")\n",
    "          .assign(hit = lambda d: d.root_true == d.root_pred)\n",
    "          .groupby(\"language\")[\"hit\"].mean()\n",
    "          .sort_values(ascending=False)\n",
    "    )\n",
    "    display(acc_by_lang)\n",
    "else:\n",
    "    print(\"labeled_test.csv not found – skipped offline scoring.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "9d7d2bc4-dcc0-4f3f-929d-14071db33cbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentences seen in >1 language: 495\n"
     ]
    }
   ],
   "source": [
    "# How many (language, sentence) pairs share the same sentence id?\n",
    "dup = test_raw.groupby('sentence')['language'].nunique()\n",
    "print(\"sentences seen in >1 language:\", (dup > 1).sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "8d87152b-b8be-47a6-ba65-1c3a97355e0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>language</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9405</th>\n",
       "      <td>9406</td>\n",
       "      <td>Arabic</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8415</th>\n",
       "      <td>8416</td>\n",
       "      <td>Chinese</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7920</th>\n",
       "      <td>7921</td>\n",
       "      <td>Czech</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1485</th>\n",
       "      <td>1486</td>\n",
       "      <td>English</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>496</td>\n",
       "      <td>Finnish</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id language  sentence\n",
       "9405  9406   Arabic         1\n",
       "8415  8416  Chinese         1\n",
       "7920  7921    Czech         1\n",
       "1485  1486  English         1\n",
       "495    496  Finnish         1"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_raw.sort_values(['sentence','language']).head(12)[['id','language','sentence']].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "4b1211d7-f928-4144-94dc-7a80f25be755",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>language</th>\n",
       "      <th>node</th>\n",
       "      <th>n_tokens</th>\n",
       "      <th>pagerank</th>\n",
       "      <th>betweenness</th>\n",
       "      <th>katz</th>\n",
       "      <th>closeness</th>\n",
       "      <th>voterank</th>\n",
       "      <th>prob</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sentence</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Japanese</td>\n",
       "      <td>38</td>\n",
       "      <td>43</td>\n",
       "      <td>0.137674</td>\n",
       "      <td>0.057698</td>\n",
       "      <td>0.021463</td>\n",
       "      <td>0.109101</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>-1.609072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Japanese</td>\n",
       "      <td>17</td>\n",
       "      <td>49</td>\n",
       "      <td>0.175358</td>\n",
       "      <td>0.119976</td>\n",
       "      <td>0.029934</td>\n",
       "      <td>0.192211</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>-0.728393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Japanese</td>\n",
       "      <td>15</td>\n",
       "      <td>38</td>\n",
       "      <td>0.232180</td>\n",
       "      <td>0.335790</td>\n",
       "      <td>0.047725</td>\n",
       "      <td>0.219844</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>-1.200192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Japanese</td>\n",
       "      <td>6</td>\n",
       "      <td>19</td>\n",
       "      <td>0.148543</td>\n",
       "      <td>0.148693</td>\n",
       "      <td>0.012601</td>\n",
       "      <td>0.151507</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>-1.559605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Japanese</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>0.493944</td>\n",
       "      <td>0.787879</td>\n",
       "      <td>0.087372</td>\n",
       "      <td>0.406272</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.477845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>985</th>\n",
       "      <td>Japanese</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>0.335636</td>\n",
       "      <td>0.200693</td>\n",
       "      <td>0.119627</td>\n",
       "      <td>0.040605</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>-0.289833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986</th>\n",
       "      <td>Japanese</td>\n",
       "      <td>16</td>\n",
       "      <td>23</td>\n",
       "      <td>0.227850</td>\n",
       "      <td>0.130492</td>\n",
       "      <td>0.247035</td>\n",
       "      <td>0.171562</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>-1.383158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987</th>\n",
       "      <td>Japanese</td>\n",
       "      <td>35</td>\n",
       "      <td>47</td>\n",
       "      <td>0.099163</td>\n",
       "      <td>0.152643</td>\n",
       "      <td>0.021459</td>\n",
       "      <td>0.175242</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>-1.304062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>991</th>\n",
       "      <td>Japanese</td>\n",
       "      <td>16</td>\n",
       "      <td>31</td>\n",
       "      <td>0.206654</td>\n",
       "      <td>0.091304</td>\n",
       "      <td>0.281230</td>\n",
       "      <td>0.164409</td>\n",
       "      <td>0.882353</td>\n",
       "      <td>-0.914346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>993</th>\n",
       "      <td>Japanese</td>\n",
       "      <td>11</td>\n",
       "      <td>21</td>\n",
       "      <td>0.134601</td>\n",
       "      <td>0.121739</td>\n",
       "      <td>0.055342</td>\n",
       "      <td>0.135054</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>-1.581381</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>495 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          language  node  n_tokens  pagerank  betweenness      katz  \\\n",
       "sentence                                                              \n",
       "1         Japanese    38        43  0.137674     0.057698  0.021463   \n",
       "3         Japanese    17        49  0.175358     0.119976  0.029934   \n",
       "4         Japanese    15        38  0.232180     0.335790  0.047725   \n",
       "6         Japanese     6        19  0.148543     0.148693  0.012601   \n",
       "7         Japanese     3        12  0.493944     0.787879  0.087372   \n",
       "...            ...   ...       ...       ...          ...       ...   \n",
       "985       Japanese     2        30  0.335636     0.200693  0.119627   \n",
       "986       Japanese    16        23  0.227850     0.130492  0.247035   \n",
       "987       Japanese    35        47  0.099163     0.152643  0.021459   \n",
       "991       Japanese    16        31  0.206654     0.091304  0.281230   \n",
       "993       Japanese    11        21  0.134601     0.121739  0.055342   \n",
       "\n",
       "          closeness  voterank      prob  \n",
       "sentence                                 \n",
       "1          0.109101  0.545455 -1.609072  \n",
       "3          0.192211  0.913043 -0.728393  \n",
       "4          0.219844  0.850000 -1.200192  \n",
       "6          0.151507  0.333333 -1.559605  \n",
       "7          0.406272  1.000000 -0.477845  \n",
       "...             ...       ...       ...  \n",
       "985        0.040605  0.933333 -0.289833  \n",
       "986        0.171562  0.583333 -1.383158  \n",
       "987        0.175242  0.727273 -1.304062  \n",
       "991        0.164409  0.882353 -0.914346  \n",
       "993        0.135054  0.333333 -1.581381  \n",
       "\n",
       "[495 rows x 9 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_nodes.groupby('sentence').first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff5e1163-ffc4-4500-b7f4-dd3e82cf7cd7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d2da54-3bd0-4690-9b22-a54a9259d5c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f133c01e-805b-416b-a021-1987f240dcf5",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'categories'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[40]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# -- make sure language categories match training --\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m df \u001b[38;5;129;01min\u001b[39;00m (test_nodes,):\n\u001b[32m      3\u001b[39m     df[\u001b[33m\"\u001b[39m\u001b[33mlanguage\u001b[39m\u001b[33m\"\u001b[39m] = pd.Categorical(\n\u001b[32m      4\u001b[39m         df[\u001b[33m\"\u001b[39m\u001b[33mlanguage\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m         categories = \u001b[43mranker_final\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfeature_name_\u001b[49m\u001b[43m[\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcategories\u001b[49m   \u001b[38;5;66;03m# last entry is language\u001b[39;00m\n\u001b[32m      6\u001b[39m     )\n\u001b[32m      8\u001b[39m FEATURES  = [\u001b[33m'\u001b[39m\u001b[33mpagerank\u001b[39m\u001b[33m'\u001b[39m,\u001b[33m'\u001b[39m\u001b[33mbetweenness\u001b[39m\u001b[33m'\u001b[39m,\u001b[33m'\u001b[39m\u001b[33mkatz\u001b[39m\u001b[33m'\u001b[39m,\u001b[33m'\u001b[39m\u001b[33mvoterank\u001b[39m\u001b[33m'\u001b[39m,\u001b[33m'\u001b[39m\u001b[33mcloseness\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m      9\u001b[39m              \u001b[33m'\u001b[39m\u001b[33mn_tokens\u001b[39m\u001b[33m'\u001b[39m,\u001b[33m'\u001b[39m\u001b[33mlanguage\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m     10\u001b[39m X_test = test_nodes[FEATURES]\n",
      "\u001b[31mAttributeError\u001b[39m: 'str' object has no attribute 'categories'"
     ]
    }
   ],
   "source": [
    "# # -- make sure language categories match training --\n",
    "# for df in (test_nodes,):\n",
    "#     df[\"language\"] = pd.Categorical(\n",
    "#         df[\"language\"],\n",
    "#         categories = ranker_final.feature_name_[-1].categories   # last entry is language\n",
    "#     )\n",
    "\n",
    "# FEATURES  = ['pagerank','betweenness','katz','voterank','closeness',\n",
    "#              'n_tokens','language']\n",
    "# X_test = test_nodes[FEATURES]\n",
    "\n",
    "# # 3. Predict a probability for every node -------------------------------\n",
    "# test_nodes[\"prob\"] = ranker_final.predict(X_test)\n",
    "\n",
    "# # 4. Pick the top node per sentence  (MAP@1 → root guess) ---------------\n",
    "# root_pred = (\n",
    "#     test_nodes\n",
    "#         .loc[test_nodes.groupby(\"sentence\")[\"prob\"].idxmax()]\n",
    "#         .loc[:, [\"sentence\", \"node\"]]\n",
    "#         .rename(columns={\"node\": \"root\"})\n",
    "# )\n",
    "\n",
    "# # 5. Build submission.csv  (Kaggle expects id,root) ---------------------\n",
    "# submission = (\n",
    "#     raw_test[[\"id\",\"sentence\"]]        # 'id' is the row identifier Kaggle gave you\n",
    "#         .merge(root_pred, on=\"sentence\", how=\"left\")\n",
    "#         .loc[:, [\"id\",\"root\"]]\n",
    "# )\n",
    "# submission.to_csv(\"submission.csv\", index=False)\n",
    "# print(\"✓ submission.csv written:\", submission.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c849a746-3d30-447a-aff0-42458d28e71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------------\n",
    "#           OPTIONAL – Offline accuracy on professor’s labels\n",
    "# -----------------------------------------------------------------------\n",
    "if Path(\"labeled_test.csv\").exists():\n",
    "    labeled = pd.read_csv(\"labeled_test.csv\")              # has columns id,sentence,root\n",
    "    merged  = labeled.merge(submission, on=\"id\", suffixes=(\"_true\",\"_pred\"))\n",
    "    sent_acc = (merged.root_true == merged.root_pred).mean()\n",
    "    print(f\"Offline sentence accuracy = {sent_acc:0.3f}\")\n",
    "\n",
    "    # (extra) Confusion table of languages\n",
    "    acc_by_lang = (\n",
    "        merged\n",
    "          .merge(raw_test[[\"id\",\"language\"]], on=\"id\")\n",
    "          .assign(hit = lambda d: d.root_true == d.root_pred)\n",
    "          .groupby(\"language\")[\"hit\"].mean()\n",
    "          .sort_values(ascending=False)\n",
    "    )\n",
    "    display(acc_by_lang)\n",
    "\n",
    "else:\n",
    "    print(\"labeled_test.csv not found – skipped offline scoring.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a9b49f-ea77-4913-952b-7edb4f4976c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ee3d15-692f-4f2c-91d5-74ff06d5a1a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4753b37-93a0-4048-81a6-50006518dda7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e16288ab-ce8d-486c-a504-b3492e331766",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eea7cdda-b7f3-485c-ad25-233be4e71b4c",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "positional argument follows keyword argument (1455971992.py, line 6)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mranker.fit(X_all, y_all, group=grp_all, categorical_feature=cat_feats, ...)\u001b[39m\n                                                                              ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m positional argument follows keyword argument\n"
     ]
    }
   ],
   "source": [
    "order_all = np.argsort(sid, kind='mergesort')\n",
    "X_all     = X_full.iloc[order_all]\n",
    "y_all     = y_full[order_all]\n",
    "grp_all   = make_groups(sid[order_all])\n",
    "\n",
    "ranker.fit(X_all, y_all, group=grp_all, categorical_feature=cat_feats, ...)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "107c0b97-ea5a-4565-8358-f1e1966ae142",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "LGBMRanker.fit() got an unexpected keyword argument 'num_boost_round'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 18\u001b[39m\n\u001b[32m      4\u001b[39m grp_all = make_groups(sid[order])\n\u001b[32m      6\u001b[39m ranker_final = lgb.LGBMRanker(\n\u001b[32m      7\u001b[39m         objective      = \u001b[33m'\u001b[39m\u001b[33mlambdarank\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m      8\u001b[39m         metric         = \u001b[33m'\u001b[39m\u001b[33mmap\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     16\u001b[39m         random_state   = \u001b[32m42\u001b[39m,\n\u001b[32m     17\u001b[39m     )\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m \u001b[43mranker_final\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX_all\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_all\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgrp_all\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcategorical_feature\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcat_feats\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     22\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_boost_round\u001b[49m\u001b[43m=\u001b[49m\u001b[43mranker\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbest_iteration_\u001b[49m\u001b[43m   \u001b[49m\u001b[38;5;66;43;03m# from CV fold with best MAP@1\u001b[39;49;00m\n\u001b[32m     23\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[31mTypeError\u001b[39m: LGBMRanker.fit() got an unexpected keyword argument 'num_boost_round'"
     ]
    }
   ],
   "source": [
    "order   = np.argsort(sid, kind='mergesort')\n",
    "X_all   = X_full.iloc[order]\n",
    "y_all   = y_full[order]\n",
    "grp_all = make_groups(sid[order])\n",
    "\n",
    "ranker_final = lgb.LGBMRanker(\n",
    "        objective      = 'lambdarank',\n",
    "        metric         = 'map',\n",
    "        label_gain     = [0, 1],\n",
    "        n_estimators   = 1500,\n",
    "        learning_rate  = 0.03,\n",
    "        num_leaves     = 127,\n",
    "        min_data_in_leaf = 20,\n",
    "        subsample      = 0.8,\n",
    "        colsample_bytree = 0.8,\n",
    "        random_state   = 42,\n",
    "    )\n",
    "ranker_final.fit(\n",
    "    X_all, y_all,\n",
    "    group=grp_all,\n",
    "    categorical_feature=cat_feats,\n",
    "    num_boost_round=ranker.best_iteration_   # from CV fold with best MAP@1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30444d45-600f-4cf7-b294-da1295e8fc9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "023e8aa0-1bd2-49da-974a-53b5276f4df1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "507b3f1d-b4eb-44ba-b8f6-d5dd5927c412",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Fatal] Sum of query counts (157986) differs from the length of #data (70852378)\n"
     ]
    },
    {
     "ename": "LightGBMError",
     "evalue": "Sum of query counts (157986) differs from the length of #data (70852378)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mLightGBMError\u001b[39m                             Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 18\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m tr, va \u001b[38;5;129;01min\u001b[39;00m gkf.split(X, y, groups):\n\u001b[32m      5\u001b[39m     ranker = LGBMRanker(\n\u001b[32m      6\u001b[39m         objective      = \u001b[33m'\u001b[39m\u001b[33mlambdarank\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m      7\u001b[39m         metric         = \u001b[33m'\u001b[39m\u001b[33mmap\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     15\u001b[39m         random_state   = \u001b[32m42\u001b[39m,\n\u001b[32m     16\u001b[39m     )\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m     \u001b[43mranker\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m.\u001b[49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtr\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtr\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m         \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroup_sizes\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtr\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[43m        \u001b[49m\u001b[43meval_set\u001b[49m\u001b[43m      \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m.\u001b[49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mva\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m[\u001b[49m\u001b[43mva\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     22\u001b[39m \u001b[43m        \u001b[49m\u001b[43meval_group\u001b[49m\u001b[43m    \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mgroup_sizes\u001b[49m\u001b[43m[\u001b[49m\u001b[43mva\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     23\u001b[39m \u001b[43m        \u001b[49m\u001b[43meval_at\u001b[49m\u001b[43m       \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     24\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcategorical_feature\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mcat_feats\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     25\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m     \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\n\u001b[32m     26\u001b[39m \u001b[43m            \u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m50\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     27\u001b[39m \u001b[43m            \u001b[49m\u001b[43mlog_evaluation\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m50\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m              \u001b[49m\u001b[38;5;66;43;03m# set to 0 for silence\u001b[39;49;00m\n\u001b[32m     28\u001b[39m \u001b[43m        \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     29\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     31\u001b[39m     \u001b[38;5;66;03m# ---------- accuracy@1 on this fold ----------\u001b[39;00m\n\u001b[32m     32\u001b[39m     prob = ranker.predict(X.iloc[va])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/omnixai/lib/python3.11/site-packages/lightgbm/sklearn.py:1780\u001b[39m, in \u001b[36mLGBMRanker.fit\u001b[39m\u001b[34m(self, X, y, sample_weight, init_score, group, eval_set, eval_names, eval_sample_weight, eval_init_score, eval_group, eval_metric, eval_at, feature_name, categorical_feature, callbacks, init_model)\u001b[39m\n\u001b[32m   1774\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1775\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mShould set group for all eval datasets for ranking task; \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1776\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mif you use dict, the index should start from 0\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1777\u001b[39m         )\n\u001b[32m   1779\u001b[39m \u001b[38;5;28mself\u001b[39m._eval_at = eval_at\n\u001b[32m-> \u001b[39m\u001b[32m1780\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1781\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1782\u001b[39m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1783\u001b[39m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1784\u001b[39m \u001b[43m    \u001b[49m\u001b[43minit_score\u001b[49m\u001b[43m=\u001b[49m\u001b[43minit_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1785\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1786\u001b[39m \u001b[43m    \u001b[49m\u001b[43meval_set\u001b[49m\u001b[43m=\u001b[49m\u001b[43meval_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1787\u001b[39m \u001b[43m    \u001b[49m\u001b[43meval_names\u001b[49m\u001b[43m=\u001b[49m\u001b[43meval_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1788\u001b[39m \u001b[43m    \u001b[49m\u001b[43meval_sample_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[43meval_sample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1789\u001b[39m \u001b[43m    \u001b[49m\u001b[43meval_init_score\u001b[49m\u001b[43m=\u001b[49m\u001b[43meval_init_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1790\u001b[39m \u001b[43m    \u001b[49m\u001b[43meval_group\u001b[49m\u001b[43m=\u001b[49m\u001b[43meval_group\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1791\u001b[39m \u001b[43m    \u001b[49m\u001b[43meval_metric\u001b[49m\u001b[43m=\u001b[49m\u001b[43meval_metric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1792\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfeature_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfeature_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1793\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcategorical_feature\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcategorical_feature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1794\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1795\u001b[39m \u001b[43m    \u001b[49m\u001b[43minit_model\u001b[49m\u001b[43m=\u001b[49m\u001b[43minit_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1796\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1797\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/omnixai/lib/python3.11/site-packages/lightgbm/sklearn.py:1049\u001b[39m, in \u001b[36mLGBMModel.fit\u001b[39m\u001b[34m(self, X, y, sample_weight, init_score, group, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_group, eval_metric, feature_name, categorical_feature, callbacks, init_model)\u001b[39m\n\u001b[32m   1046\u001b[39m evals_result: _EvalResultDict = {}\n\u001b[32m   1047\u001b[39m callbacks.append(record_evaluation(evals_result))\n\u001b[32m-> \u001b[39m\u001b[32m1049\u001b[39m \u001b[38;5;28mself\u001b[39m._Booster = \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1050\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1051\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_set\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1052\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_boost_round\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mn_estimators\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1053\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalid_sets\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvalid_sets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1054\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalid_names\u001b[49m\u001b[43m=\u001b[49m\u001b[43meval_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1055\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfeval\u001b[49m\u001b[43m=\u001b[49m\u001b[43meval_metrics_callable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[32m   1056\u001b[39m \u001b[43m    \u001b[49m\u001b[43minit_model\u001b[49m\u001b[43m=\u001b[49m\u001b[43minit_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1057\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1058\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1060\u001b[39m \u001b[38;5;66;03m# This populates the property self.n_features_, the number of features in the fitted model,\u001b[39;00m\n\u001b[32m   1061\u001b[39m \u001b[38;5;66;03m# and so should only be set after fitting.\u001b[39;00m\n\u001b[32m   1062\u001b[39m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m   1063\u001b[39m \u001b[38;5;66;03m# The related property self._n_features_in, which populates self.n_features_in_,\u001b[39;00m\n\u001b[32m   1064\u001b[39m \u001b[38;5;66;03m# is set BEFORE fitting.\u001b[39;00m\n\u001b[32m   1065\u001b[39m \u001b[38;5;28mself\u001b[39m._n_features = \u001b[38;5;28mself\u001b[39m._Booster.num_feature()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/omnixai/lib/python3.11/site-packages/lightgbm/engine.py:297\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m(params, train_set, num_boost_round, valid_sets, valid_names, feval, init_model, keep_training_booster, callbacks)\u001b[39m\n\u001b[32m    295\u001b[39m \u001b[38;5;66;03m# construct booster\u001b[39;00m\n\u001b[32m    296\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m297\u001b[39m     booster = \u001b[43mBooster\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_set\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain_set\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    298\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_valid_contain_train:\n\u001b[32m    299\u001b[39m         booster.set_train_data_name(train_data_name)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/omnixai/lib/python3.11/site-packages/lightgbm/basic.py:3656\u001b[39m, in \u001b[36mBooster.__init__\u001b[39m\u001b[34m(self, params, train_set, model_file, model_str)\u001b[39m\n\u001b[32m   3649\u001b[39m     \u001b[38;5;28mself\u001b[39m.set_network(\n\u001b[32m   3650\u001b[39m         machines=machines,\n\u001b[32m   3651\u001b[39m         local_listen_port=params[\u001b[33m\"\u001b[39m\u001b[33mlocal_listen_port\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m   3652\u001b[39m         listen_time_out=params.get(\u001b[33m\"\u001b[39m\u001b[33mtime_out\u001b[39m\u001b[33m\"\u001b[39m, \u001b[32m120\u001b[39m),\n\u001b[32m   3653\u001b[39m         num_machines=params[\u001b[33m\"\u001b[39m\u001b[33mnum_machines\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m   3654\u001b[39m     )\n\u001b[32m   3655\u001b[39m \u001b[38;5;66;03m# construct booster object\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m3656\u001b[39m \u001b[43mtrain_set\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconstruct\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3657\u001b[39m \u001b[38;5;66;03m# copy the parameters from train_set\u001b[39;00m\n\u001b[32m   3658\u001b[39m params.update(train_set.get_params())\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/omnixai/lib/python3.11/site-packages/lightgbm/basic.py:2590\u001b[39m, in \u001b[36mDataset.construct\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   2585\u001b[39m             \u001b[38;5;28mself\u001b[39m._set_init_score_by_predictor(\n\u001b[32m   2586\u001b[39m                 predictor=\u001b[38;5;28mself\u001b[39m._predictor, data=\u001b[38;5;28mself\u001b[39m.data, used_indices=used_indices\n\u001b[32m   2587\u001b[39m             )\n\u001b[32m   2588\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2589\u001b[39m     \u001b[38;5;66;03m# create train\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2590\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_lazy_init\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2591\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2592\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2593\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreference\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   2594\u001b[39m \u001b[43m        \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2595\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2596\u001b[39m \u001b[43m        \u001b[49m\u001b[43minit_score\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43minit_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2597\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpredictor\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_predictor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2598\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfeature_name\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfeature_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2599\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcategorical_feature\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcategorical_feature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2600\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2601\u001b[39m \u001b[43m        \u001b[49m\u001b[43mposition\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mposition\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2602\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2603\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.free_raw_data:\n\u001b[32m   2604\u001b[39m     \u001b[38;5;28mself\u001b[39m.data = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/omnixai/lib/python3.11/site-packages/lightgbm/basic.py:2215\u001b[39m, in \u001b[36mDataset._lazy_init\u001b[39m\u001b[34m(self, data, label, reference, weight, group, init_score, predictor, feature_name, categorical_feature, params, position)\u001b[39m\n\u001b[32m   2213\u001b[39m     \u001b[38;5;28mself\u001b[39m.set_weight(weight)\n\u001b[32m   2214\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m group \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2215\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mset_group\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2216\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m position \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   2217\u001b[39m     \u001b[38;5;28mself\u001b[39m.set_position(position)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/omnixai/lib/python3.11/site-packages/lightgbm/basic.py:3161\u001b[39m, in \u001b[36mDataset.set_group\u001b[39m\u001b[34m(self, group)\u001b[39m\n\u001b[32m   3159\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_pyarrow_array(group):\n\u001b[32m   3160\u001b[39m     group = _list_to_1d_numpy(group, dtype=np.int32, name=\u001b[33m\"\u001b[39m\u001b[33mgroup\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m3161\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mset_field\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgroup\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3162\u001b[39m \u001b[38;5;66;03m# original values can be modified at cpp side\u001b[39;00m\n\u001b[32m   3163\u001b[39m constructed_group = \u001b[38;5;28mself\u001b[39m.get_field(\u001b[33m\"\u001b[39m\u001b[33mgroup\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/omnixai/lib/python3.11/site-packages/lightgbm/basic.py:2847\u001b[39m, in \u001b[36mDataset.set_field\u001b[39m\u001b[34m(self, field_name, data)\u001b[39m\n\u001b[32m   2845\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m type_data != _FIELD_TYPE_MAPPER[field_name]:\n\u001b[32m   2846\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mInput type error for set_field\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m2847\u001b[39m \u001b[43m_safe_call\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2848\u001b[39m \u001b[43m    \u001b[49m\u001b[43m_LIB\u001b[49m\u001b[43m.\u001b[49m\u001b[43mLGBM_DatasetSetField\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2849\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2850\u001b[39m \u001b[43m        \u001b[49m\u001b[43m_c_str\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfield_name\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2851\u001b[39m \u001b[43m        \u001b[49m\u001b[43mptr_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2852\u001b[39m \u001b[43m        \u001b[49m\u001b[43mctypes\u001b[49m\u001b[43m.\u001b[49m\u001b[43mc_int\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2853\u001b[39m \u001b[43m        \u001b[49m\u001b[43mctypes\u001b[49m\u001b[43m.\u001b[49m\u001b[43mc_int\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtype_data\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2854\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2855\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2856\u001b[39m \u001b[38;5;28mself\u001b[39m.version += \u001b[32m1\u001b[39m\n\u001b[32m   2857\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/omnixai/lib/python3.11/site-packages/lightgbm/basic.py:313\u001b[39m, in \u001b[36m_safe_call\u001b[39m\u001b[34m(ret)\u001b[39m\n\u001b[32m    305\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Check the return value from C API call.\u001b[39;00m\n\u001b[32m    306\u001b[39m \n\u001b[32m    307\u001b[39m \u001b[33;03mParameters\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    310\u001b[39m \u001b[33;03m    The return value from C API calls.\u001b[39;00m\n\u001b[32m    311\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    312\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ret != \u001b[32m0\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m313\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m LightGBMError(_LIB.LGBM_GetLastError().decode(\u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m))\n",
      "\u001b[31mLightGBMError\u001b[39m: Sum of query counts (157986) differs from the length of #data (70852378)"
     ]
    }
   ],
   "source": [
    "gkf = GroupKFold(5)\n",
    "val_acc = []\n",
    "\n",
    "for tr, va in gkf.split(X, y, groups):\n",
    "    ranker = LGBMRanker(\n",
    "        objective      = 'lambdarank',\n",
    "        metric         = 'map',\n",
    "        label_gain     = [0, 1],\n",
    "        n_estimators   = 1500,\n",
    "        learning_rate  = 0.03,\n",
    "        num_leaves     = 127,\n",
    "        min_data_in_leaf = 20,\n",
    "        subsample      = 0.8,\n",
    "        colsample_bytree = 0.8,\n",
    "        random_state   = 42,\n",
    "    )\n",
    "\n",
    "    ranker.fit(\n",
    "        X.iloc[tr], y[tr],\n",
    "        group         = group_sizes[tr],\n",
    "        eval_set      = [(X.iloc[va], y[va])],\n",
    "        eval_group    = [group_sizes[va]],\n",
    "        eval_at       = [1],\n",
    "        categorical_feature = cat_feats,\n",
    "        callbacks     = [\n",
    "            early_stopping(50),\n",
    "            log_evaluation(50)              # set to 0 for silence\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    # ---------- accuracy@1 on this fold ----------\n",
    "    prob = ranker.predict(X.iloc[va])\n",
    "    sent_acc = (\n",
    "        train_nodes.iloc[va]                  # same rows\n",
    "                   .assign(prob=prob)\n",
    "                   .groupby('sentence')\n",
    "                   .apply(lambda g: g.loc[g.prob.idxmax(), 'target'])\n",
    "                   .mean()\n",
    "    )\n",
    "    val_acc.append(sent_acc)\n",
    "    print(f\"fold accuracy@1 : {sent_acc:.3f}\")\n",
    "\n",
    "print(\"CV accuracy@1 :\", np.mean(val_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "616db06f-1fac-4573-9dde-ed80b1fb59c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "94fdf563-3a9c-473e-90b3-e00d31f835b9",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "pandas dtypes must be int, float or bool.\nFields with bad pandas dtypes: language: object",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 77\u001b[39m\n\u001b[32m     64\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m tr,va \u001b[38;5;129;01min\u001b[39;00m gkf.split(X,y,groups):\n\u001b[32m     65\u001b[39m     model=lgb.LGBMRanker(\n\u001b[32m     66\u001b[39m         objective=\u001b[33m'\u001b[39m\u001b[33mlambdarank\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m     67\u001b[39m         metric=\u001b[33m'\u001b[39m\u001b[33mmap\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     75\u001b[39m         random_state=\u001b[32m42\u001b[39m,\n\u001b[32m     76\u001b[39m     )\n\u001b[32m---> \u001b[39m\u001b[32m77\u001b[39m     \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m    \u001b[49m\n\u001b[32m     78\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m.\u001b[49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtr\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtr\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     79\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup_sizes\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtr\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     80\u001b[39m \u001b[43m        \u001b[49m\u001b[43meval_set\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m.\u001b[49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mva\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m[\u001b[49m\u001b[43mva\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     81\u001b[39m \u001b[43m        \u001b[49m\u001b[43meval_group\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mgroup_sizes\u001b[49m\u001b[43m[\u001b[49m\u001b[43mva\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     82\u001b[39m \u001b[43m        \u001b[49m\u001b[43meval_at\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     83\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcategorical_feature\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcat_feats\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     84\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\n\u001b[32m     85\u001b[39m \u001b[43m        \u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m50\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     86\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlog_evaluation\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m50\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# 0 = silent; set to 10 for every 10 rounds\u001b[39;49;00m\n\u001b[32m     87\u001b[39m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m     88\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     89\u001b[39m     prob=model.predict(X.iloc[va])\n\u001b[32m     90\u001b[39m     pred_proba[va]=prob\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/omnixai/lib/python3.11/site-packages/lightgbm/sklearn.py:1780\u001b[39m, in \u001b[36mLGBMRanker.fit\u001b[39m\u001b[34m(self, X, y, sample_weight, init_score, group, eval_set, eval_names, eval_sample_weight, eval_init_score, eval_group, eval_metric, eval_at, feature_name, categorical_feature, callbacks, init_model)\u001b[39m\n\u001b[32m   1774\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1775\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mShould set group for all eval datasets for ranking task; \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1776\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mif you use dict, the index should start from 0\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1777\u001b[39m         )\n\u001b[32m   1779\u001b[39m \u001b[38;5;28mself\u001b[39m._eval_at = eval_at\n\u001b[32m-> \u001b[39m\u001b[32m1780\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1781\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1782\u001b[39m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1783\u001b[39m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1784\u001b[39m \u001b[43m    \u001b[49m\u001b[43minit_score\u001b[49m\u001b[43m=\u001b[49m\u001b[43minit_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1785\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1786\u001b[39m \u001b[43m    \u001b[49m\u001b[43meval_set\u001b[49m\u001b[43m=\u001b[49m\u001b[43meval_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1787\u001b[39m \u001b[43m    \u001b[49m\u001b[43meval_names\u001b[49m\u001b[43m=\u001b[49m\u001b[43meval_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1788\u001b[39m \u001b[43m    \u001b[49m\u001b[43meval_sample_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[43meval_sample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1789\u001b[39m \u001b[43m    \u001b[49m\u001b[43meval_init_score\u001b[49m\u001b[43m=\u001b[49m\u001b[43meval_init_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1790\u001b[39m \u001b[43m    \u001b[49m\u001b[43meval_group\u001b[49m\u001b[43m=\u001b[49m\u001b[43meval_group\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1791\u001b[39m \u001b[43m    \u001b[49m\u001b[43meval_metric\u001b[49m\u001b[43m=\u001b[49m\u001b[43meval_metric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1792\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfeature_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfeature_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1793\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcategorical_feature\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcategorical_feature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1794\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1795\u001b[39m \u001b[43m    \u001b[49m\u001b[43minit_model\u001b[49m\u001b[43m=\u001b[49m\u001b[43minit_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1796\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1797\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/omnixai/lib/python3.11/site-packages/lightgbm/sklearn.py:1049\u001b[39m, in \u001b[36mLGBMModel.fit\u001b[39m\u001b[34m(self, X, y, sample_weight, init_score, group, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_group, eval_metric, feature_name, categorical_feature, callbacks, init_model)\u001b[39m\n\u001b[32m   1046\u001b[39m evals_result: _EvalResultDict = {}\n\u001b[32m   1047\u001b[39m callbacks.append(record_evaluation(evals_result))\n\u001b[32m-> \u001b[39m\u001b[32m1049\u001b[39m \u001b[38;5;28mself\u001b[39m._Booster = \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1050\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1051\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_set\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1052\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_boost_round\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mn_estimators\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1053\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalid_sets\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvalid_sets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1054\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalid_names\u001b[49m\u001b[43m=\u001b[49m\u001b[43meval_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1055\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfeval\u001b[49m\u001b[43m=\u001b[49m\u001b[43meval_metrics_callable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[32m   1056\u001b[39m \u001b[43m    \u001b[49m\u001b[43minit_model\u001b[49m\u001b[43m=\u001b[49m\u001b[43minit_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1057\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1058\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1060\u001b[39m \u001b[38;5;66;03m# This populates the property self.n_features_, the number of features in the fitted model,\u001b[39;00m\n\u001b[32m   1061\u001b[39m \u001b[38;5;66;03m# and so should only be set after fitting.\u001b[39;00m\n\u001b[32m   1062\u001b[39m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m   1063\u001b[39m \u001b[38;5;66;03m# The related property self._n_features_in, which populates self.n_features_in_,\u001b[39;00m\n\u001b[32m   1064\u001b[39m \u001b[38;5;66;03m# is set BEFORE fitting.\u001b[39;00m\n\u001b[32m   1065\u001b[39m \u001b[38;5;28mself\u001b[39m._n_features = \u001b[38;5;28mself\u001b[39m._Booster.num_feature()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/omnixai/lib/python3.11/site-packages/lightgbm/engine.py:297\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m(params, train_set, num_boost_round, valid_sets, valid_names, feval, init_model, keep_training_booster, callbacks)\u001b[39m\n\u001b[32m    295\u001b[39m \u001b[38;5;66;03m# construct booster\u001b[39;00m\n\u001b[32m    296\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m297\u001b[39m     booster = \u001b[43mBooster\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_set\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain_set\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    298\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_valid_contain_train:\n\u001b[32m    299\u001b[39m         booster.set_train_data_name(train_data_name)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/omnixai/lib/python3.11/site-packages/lightgbm/basic.py:3656\u001b[39m, in \u001b[36mBooster.__init__\u001b[39m\u001b[34m(self, params, train_set, model_file, model_str)\u001b[39m\n\u001b[32m   3649\u001b[39m     \u001b[38;5;28mself\u001b[39m.set_network(\n\u001b[32m   3650\u001b[39m         machines=machines,\n\u001b[32m   3651\u001b[39m         local_listen_port=params[\u001b[33m\"\u001b[39m\u001b[33mlocal_listen_port\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m   3652\u001b[39m         listen_time_out=params.get(\u001b[33m\"\u001b[39m\u001b[33mtime_out\u001b[39m\u001b[33m\"\u001b[39m, \u001b[32m120\u001b[39m),\n\u001b[32m   3653\u001b[39m         num_machines=params[\u001b[33m\"\u001b[39m\u001b[33mnum_machines\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m   3654\u001b[39m     )\n\u001b[32m   3655\u001b[39m \u001b[38;5;66;03m# construct booster object\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m3656\u001b[39m \u001b[43mtrain_set\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconstruct\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3657\u001b[39m \u001b[38;5;66;03m# copy the parameters from train_set\u001b[39;00m\n\u001b[32m   3658\u001b[39m params.update(train_set.get_params())\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/omnixai/lib/python3.11/site-packages/lightgbm/basic.py:2590\u001b[39m, in \u001b[36mDataset.construct\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   2585\u001b[39m             \u001b[38;5;28mself\u001b[39m._set_init_score_by_predictor(\n\u001b[32m   2586\u001b[39m                 predictor=\u001b[38;5;28mself\u001b[39m._predictor, data=\u001b[38;5;28mself\u001b[39m.data, used_indices=used_indices\n\u001b[32m   2587\u001b[39m             )\n\u001b[32m   2588\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2589\u001b[39m     \u001b[38;5;66;03m# create train\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2590\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_lazy_init\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2591\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2592\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2593\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreference\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   2594\u001b[39m \u001b[43m        \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2595\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2596\u001b[39m \u001b[43m        \u001b[49m\u001b[43minit_score\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43minit_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2597\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpredictor\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_predictor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2598\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfeature_name\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfeature_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2599\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcategorical_feature\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcategorical_feature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2600\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2601\u001b[39m \u001b[43m        \u001b[49m\u001b[43mposition\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mposition\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2602\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2603\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.free_raw_data:\n\u001b[32m   2604\u001b[39m     \u001b[38;5;28mself\u001b[39m.data = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/omnixai/lib/python3.11/site-packages/lightgbm/basic.py:2123\u001b[39m, in \u001b[36mDataset._lazy_init\u001b[39m\u001b[34m(self, data, label, reference, weight, group, init_score, predictor, feature_name, categorical_feature, params, position)\u001b[39m\n\u001b[32m   2121\u001b[39m     categorical_feature = reference.categorical_feature\n\u001b[32m   2122\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, pd_DataFrame):\n\u001b[32m-> \u001b[39m\u001b[32m2123\u001b[39m     data, feature_name, categorical_feature, \u001b[38;5;28mself\u001b[39m.pandas_categorical = \u001b[43m_data_from_pandas\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2124\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2125\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfeature_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfeature_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2126\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcategorical_feature\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcategorical_feature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2127\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpandas_categorical\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpandas_categorical\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2128\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2129\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m _is_pyarrow_table(data) \u001b[38;5;129;01mand\u001b[39;00m feature_name == \u001b[33m\"\u001b[39m\u001b[33mauto\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m   2130\u001b[39m     feature_name = data.column_names\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/omnixai/lib/python3.11/site-packages/lightgbm/basic.py:868\u001b[39m, in \u001b[36m_data_from_pandas\u001b[39m\u001b[34m(data, feature_name, categorical_feature, pandas_categorical)\u001b[39m\n\u001b[32m    864\u001b[39m df_dtypes.append(np.float32)\n\u001b[32m    865\u001b[39m target_dtype = np.result_type(*df_dtypes)\n\u001b[32m    867\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[32m--> \u001b[39m\u001b[32m868\u001b[39m     \u001b[43m_pandas_to_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_dtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtarget_dtype\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m    869\u001b[39m     feature_name,\n\u001b[32m    870\u001b[39m     categorical_feature,\n\u001b[32m    871\u001b[39m     pandas_categorical,\n\u001b[32m    872\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/omnixai/lib/python3.11/site-packages/lightgbm/basic.py:814\u001b[39m, in \u001b[36m_pandas_to_numpy\u001b[39m\u001b[34m(data, target_dtype)\u001b[39m\n\u001b[32m    810\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_pandas_to_numpy\u001b[39m(\n\u001b[32m    811\u001b[39m     data: pd_DataFrame,\n\u001b[32m    812\u001b[39m     target_dtype: \u001b[33m\"\u001b[39m\u001b[33mnp.typing.DTypeLike\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    813\u001b[39m ) -> np.ndarray:\n\u001b[32m--> \u001b[39m\u001b[32m814\u001b[39m     \u001b[43m_check_for_bad_pandas_dtypes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdtypes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    815\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    816\u001b[39m         \u001b[38;5;66;03m# most common case (no nullable dtypes)\u001b[39;00m\n\u001b[32m    817\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m data.to_numpy(dtype=target_dtype, copy=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/omnixai/lib/python3.11/site-packages/lightgbm/basic.py:805\u001b[39m, in \u001b[36m_check_for_bad_pandas_dtypes\u001b[39m\u001b[34m(pandas_dtypes_series)\u001b[39m\n\u001b[32m    799\u001b[39m bad_pandas_dtypes = [\n\u001b[32m    800\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcolumn_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpandas_dtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    801\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m column_name, pandas_dtype \u001b[38;5;129;01min\u001b[39;00m pandas_dtypes_series.items()\n\u001b[32m    802\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_allowed_numpy_dtype(pandas_dtype.type)\n\u001b[32m    803\u001b[39m ]\n\u001b[32m    804\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m bad_pandas_dtypes:\n\u001b[32m--> \u001b[39m\u001b[32m805\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    806\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mpandas dtypes must be int, float or bool.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mFields with bad pandas dtypes: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m, \u001b[39m\u001b[33m'\u001b[39m.join(bad_pandas_dtypes)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    807\u001b[39m     )\n",
      "\u001b[31mValueError\u001b[39m: pandas dtypes must be int, float or bool.\nFields with bad pandas dtypes: language: object"
     ]
    }
   ],
   "source": [
    "gkf = GroupKFold(n_splits=5)\n",
    "val_scores=[]\n",
    "pred_proba=np.zeros(len(X))\n",
    "\n",
    "for tr,va in gkf.split(X,y,groups):\n",
    "    model=lgb.LGBMRanker(\n",
    "        objective='lambdarank',\n",
    "        metric='map',\n",
    "        label_gain=[0,1],\n",
    "        n_estimators=1500,\n",
    "        learning_rate=0.03,\n",
    "        num_leaves=127,\n",
    "        min_data_in_leaf=20,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        random_state=42,\n",
    "    )\n",
    "    model.fit(    \n",
    "        X.iloc[tr], y[tr],\n",
    "        group=group_sizes[tr],\n",
    "        eval_set=[(X.iloc[va], y[va])],\n",
    "        eval_group=[group_sizes[va]],\n",
    "        eval_at=[1],\n",
    "        categorical_feature=cat_feats,\n",
    "        callbacks=[\n",
    "        early_stopping(50),\n",
    "        log_evaluation(50)  # 0 = silent; set to 10 for every 10 rounds\n",
    "        ]\n",
    "    )\n",
    "    prob=model.predict(X.iloc[va])\n",
    "    pred_proba[va]=prob\n",
    "    # accuracy@1\n",
    "    sent_pred=(train_nodes.iloc[va]\n",
    "               .assign(prob=prob)\n",
    "               .groupby('sentence')\n",
    "               .apply(lambda g: g.loc[g.prob.idxmax(),'target'])\n",
    "               .values)\n",
    "    acc=sent_pred.mean()\n",
    "    val_scores.append(acc)\n",
    "    print(f'fold acc: {acc:.3f}')\n",
    "\n",
    "print('CV accuracy@1',np.mean(val_scores))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2badea62-ab9f-4bbf-92ee-0cccc9032b96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50169f10-415f-419a-a75d-552f7ab680b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "gkf = GroupKFold(n_splits=5)\n",
    "val_scores=[]\n",
    "pred_proba=np.zeros(len(X))\n",
    "\n",
    "for tr,va in gkf.split(X,y,groups):\n",
    "    model=lgb.LGBMRanker(\n",
    "        objective='lambdarank',\n",
    "        metric='map',\n",
    "        label_gain=[0,1],\n",
    "        n_estimators=1500,\n",
    "        learning_rate=0.03,\n",
    "        num_leaves=127,\n",
    "        min_data_in_leaf=20,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        random_state=42,\n",
    "    )\n",
    "    model.fit(    \n",
    "        X.iloc[tr], y[tr],\n",
    "        group=group_sizes[tr],\n",
    "        eval_set=[(X.iloc[va], y[va])],\n",
    "        eval_group=[group_sizes[va]],\n",
    "        eval_at=[1],\n",
    "        categorical_feature=cat_feats,\n",
    "        callbacks=[\n",
    "        early_stopping(50),\n",
    "        log_evaluation(50)  # 0 = silent; set to 10 for every 10 rounds\n",
    "        ]\n",
    "    )\n",
    "    prob=model.predict(X.iloc[va])\n",
    "    pred_proba[va]=prob\n",
    "    # accuracy@1\n",
    "    sent_pred=(train_nodes.iloc[va]\n",
    "               .assign(prob=prob)\n",
    "               .groupby('sentence')\n",
    "               .apply(lambda g: g.loc[g.prob.idxmax(),'target'])\n",
    "               .values)\n",
    "    acc=sent_pred.mean()\n",
    "    val_scores.append(acc)\n",
    "    print(f'fold acc: {acc:.3f}')\n",
    "\n",
    "print('CV accuracy@1',np.mean(val_scores))\n",
    "\n",
    "Why is this code not saving the models?\n",
    "How can I later choose the best one? How can I create a submission? How can I apply it to test data?\n",
    "\n",
    "Please, give me the full code!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (omnixai)",
   "language": "python",
   "name": "omnixai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
